## The methods developed to capture attention

The fact that attention is a finite resource is not a problem in itself. Aiming to efficiently convey information has a long tradition with diverse methods, from the ancient Latin book Rhetorica ad Herennium[^26] through newspapers to Wikipedia. However, these were not designed for engagement per se, unlike what seems to be happening nowadays, when “there are literally billions of dollars being spent to figure out how to get you to look at one thing over another.” [^27] Why and how did it become so important to be noticed just for the sake of it?

The first instance of using attention as a success metric was in a paper of Sergey Brin and Lawrence Page titled The Anatomy of a Large-Scale Hypertextual Web Search Engine[^28]. Unlike Google, other search engines at the time produced “results \[that\] are often amusing and expand users’ horizons, \[but\] they are often frustrating and consume precious time.” [^29] (Note how spending time unnecessarily is yet considered a failure, not a success metric.[^30]) How the PageRank algorithm deemed a result relevant or not was, among other factors, to apply the existing model of counting the number of academic citations to a certain publication, and the importance of those publications referencing to the original one. This way PageRank could measure how much these sites were in the center of attention; the links pointing to a certain site and the number of its visitors became a success metric. However, as Brin and Page point out in the same paper, they “expect that advertising funded search engines will be inherently biased towards the advertisers and away from the needs of the consumers.” [^31] Google’s mission statement to “\[o\]rganize the world’s information and make it universally accessible and useful” [^32] for everyone is contradictory to giving preferential treatment to advertisers.

Companies will say that their goal is to make the world open and connected or whatever. \[...\] But if you were to actually look at the dashboards that they’re designing, the high-level metrics they’re designing for, you probably wouldn’t see those things.[^33]

Two key factors of the attention economy that I wish to emphasize here emerged with the spread of Google Inc.: using attention in some form as a success metric, and separating users and their needs from customers and their wishes, internally prioritising the latter with high-level design metrics, while communicating the former to the public in generous marketing claims, inspiring other digital companies to do the same.[^34]

To see another important factor for the attention economy emerge, we have to jump to the appearance of social networks, when considering time spent on a site became a success metric, with a prominent place in their annual reports. Facebook competes to “provide social and communication products and services that are designed to engage users and capture time spent on mobile devices and online.” [^35] Or take Tencent’s goal “to engage a large pool of casual gamers and gradually advance them to mid-core and hard-core categories”, as declared in their 2016 Annual Report.[^36] As for Twitter user’s level of engagement and ad engagement, it is critical to its success,[^37] as their revenue comes from advertisers. If these explicit goals are not transparent enough, Sean Parker (president of Facebook between 2004 and 2006), acknowledged in 2017 that the company’s intention while building the product was to “consume as much of your time and conscious attention as possible”,[^38] that they are “exploiting a vulnerability in human psychology” and that they also “understood this, consciously, and \[...\] did it anyway.” Tristan Harris, former design ethicist at Google, concurs with Parker’s assessment: “\[product designers\] play your psychological vulnerabilities (consciously and unconsciously) against you in the race to grab your attention.”

When looking for evidence of their efforts, there are plenty of examples to choose from. The bottomless feeds–used e.g. by Twitter or Facebook–present themselves as particularly rich sources of information in order to delay our transfer to the next source; they also became a content delivery standard in the industry. The reverse chronological order visible on the timestamp of each post evokes an unnecessary sense of urgency and immediacy. Notifications use similar or identical signals within an application, regardless of the importance and urgency (if at all) of the content. Some social media platforms even introduced pseudo-notifications: these can be a marketing message from the platform itself, other user’s activities or a suggestion based on accumulated data about the user[^39], all coming through the same channel where we interact with real people.

Video streaming services are also guilty in deliberately exploiting vulnerabilities of attention and self-control to increase user’s time spent in front of their content. Netflix actively encourages binge-watching its content (movies and TV series) by small design tricks, such as opting out of streaming the new video instead of actively starting it, and they are not alone: YouTube also starts autoplaying the next video on the recommendation list, unless the user actively opts out.

As we have seen in the previous part of this research, the mind comes with quite a few particular features that can be exploited: its goal-setting capabilities are stronger than its goal-enacting ones, it is susceptible to interferences, it considers information as a reward and it tries to maximize its consumption in the short term. Sending out an average of 63.5 notifications a day[^40] (for Android devices, no similar data found for iOS) is an aggressive way to draw on our craving for information in order to distract from or interrupt in whatever we are engaged in at the moment. Receiving so many external, bottom-up triggers trying to catch our attention has prompted some designers and engineers to build tools to manage all the interruptions (e.g. from the control center of the iPhone or in the application’s settings) and move from sound notifications to visual ones,[^41] similar to how ad-blockers for desktop browsers became popular to control the irrelevant commercial information.

Since external notifications turned out to be relatively manageable and avoidable, they can’t account for all the times we reach for the phone. However, internal triggers like boredom (which, as you may recall, is the second most reported reason to engage with smartphones[^42]) are much harder to neutralize. It is indeed possible to ‘design a habit’ just by following the instructions listed in Hooked[^43], Nir Eyal’s book detailing how to gain and retain users of a product and increase engagement in four steps. The cycle starts with a trigger, external in the beginning (e.g. getting a notification about a new follower), and becoming internal if the method is correctly applied (feeling a momentary pang of boredom or loneliness). This trigger prompts an action (like opening Twitter when having some time to kill), retrieving a variable reward. The small dose of surprise in what we will exactly receive prevents the product from becoming predictable and keeps holding the user’s attention again and again (e.g. browsing different content each time the user opens her News Feed). The last step closes the loop: right after the positive interaction some kind of investment (data, money, effort) is asked from the user, promising an improvement in the service for next time (e.g. following people to customize displayed content). After repeating this cycle a few times, the user most likely will develop an internal trigger thanks to the combination of the following elements: creating the mental association for the product as a relief from some kind of frustration, boredom or another uncomfortable internal state; providing a variable reward that the user will start craving; and extracting some investments from the user (time, effort, data) that ties him to this product. The mental association can partially or wholly replace the external triggers (advertisements, notifications) with the internal emotional micro-needs of the user. As Nir Eyal states, “\[t\]he habit-forming products we use are \[...\] there to provide some sort of relief.” [^44]

Undergoing the cycle of trigger, action, variable reward and investment creates a more personalized product experience each time, and strengthens a habit, slowly but surely turning new users into frequent and then compulsive users. Pondering whether this habit adds not just instant gratification or temporary relief, but substantial value to a person’s life is obviously not included in Eyal’s description. He would rather trust the conscience of designers, product managers and engineers[^45], which seems rather ironic after having described in great detail how to create habit-forming or addictive products, in principle enabling anyone, regardless of their intentions, to design a habit for others. Eyals ‘ethical guideline’, the Manipulation Matrix, includes only 2 yes-no questions: whether the product materially improves the user’s life, and whether the maker is also a user. The only case when he disapproves of using habit-forming methods if it is the case of a double ‘no’. One should note that applying this matrix would mean that all the methods of Facebook are ethical by definition, since Mark Zuckerberg has his own profile; but perhaps it is rather unrealistic to expect individuals to self-examine and then modify their behavior accordingly when faced with carefully engineered practices that promote unreflective action.

Ethical design in the attention economy

The Ethical Design Manifesto[^46] of ind.ie, a tiny social enterprise founded by Aral Balkan (and others), provides a comprehensive summary to check all aspects of a certain product’s or company’s ethical impact. The three levels of the manifesto are arranged as a pyramid, where human experience (note the using the word ‘human’ instead of ‘user’ or ‘consumer’) is just the top of the structure.



Human rights

Human effort

Human experience

Technology that respects human rights is decentralised, peer-to-peer, zero-knowledge, end-to-end encrypted, free and open source, interoperable, accessible, and sustainable.

It respects and protects your civil liberties, reduces inequality, and benefits democracy.

Technology that respects human effort is functional, convenient, and reliable.

It is thoughtful and accommodating; not arrogant or demanding. It understands that you might be distracted or differently-abled. It respects the limited time you have on this planet.

Technology that respects human experience is beautiful, magical, and delightful.

It just works. It’s intuitive. It’s invisible. It recedes into the background of your life. It gives you joy. It empowers you with superpowers. It puts a smile on your face and makes your life better.

Although Balkan is mainly worried about the ownership of user’s data, there are several components relevant to attention on all three levels, which I have highlighted above. Balkan puts privacy and ownership of information forward; he cites Shoshana Zuboff’s term ‘Surveillance Capitalism’,[^47] where hooking users to a digital product is instrumental to ‘farm’ them for all the digital information they leave behind. However, the main problem, according to James Williams (a doctoral researcher at the Oxford Internet Institute and the cofounder of the Time Well Spent movement) is exploiting psychological biases. Digital products and services “move us toward goals that may or may not align with our own \[...\] the core challenge of the Internet is that it optimizes more for our impulses than our intentions” [^48]. This disparity is the main concern of the Time Well Spent movement[^49], a “non-profit organization dedicated to creating a humane future where technology is in harmony with our well-being, our social values, and our democratic principles” [^50] founded by Tristan Harris and James Williams. The movement is working to change the situation on three different levels at the same time: empower users, so their choices pressure businesses to change; empower designers to create better products and advocate in their companies for change; and demand governmental pressure for more humane business models and to advise for better policies on user protection.[^51]

To see how the attention economy can threaten well-being, social values, and democratic principles, all depending on several variables, we need to revisit the conclusions of the first part of this research: interferences eating up our limited cognitive capacity, and our information consumption habits, to see how they play out in the long term.

---

[^26] With an English translation by Harry Caplan. Ad C. Herennium. De Ratione Dicendi (Rhetorica Ad Herennium.). Cambridge, Mass. Harvard University Press, 1954.

[^27] Williams, J. Why It’s OK to Block Ads. Practical Ethics. blog.practicalethics.ox.ac.uk/2015/10/why-its-ok-to-block-ads/ (accessed January 1, 2018)

[^28] Brin, S. and Page, L: “The Anatomy of a Large-Scale Hypertextual Web Search Engine” (1998) infolab.stanford.edu/~backrub/google.html (accessed January 1, 2018)

[^29] Ibid.

[^30] Justin Rosenstein, an ex-employee of Google mentions this in Building Organic Software in a Fast-Food Nation. 16/02/2017, Medium.com
journal.thriveglobal.com/building-organic-software-in-a-fast-food-nation-34a8197b1e2e (accessed January 23, 2018)

[^31] Brin, S. and Page, L: “The Anatomy of a Large-Scale Hypertextual Web Search Engine” (1998)infolab.stanford.edu/~backrub/google.html (accessed January 1, 2018)

[^32] Google. Our company. google.com/intl/en/about/our-company/ (accessed January 1, 2018)

[^33] Williams, James interviewed by Gallagher, Brian. Modern Media Is a DoS Attack on Your Free Will. Nautilus, Sep 21, 2017. (accessed January 25, 2018) nautil.us/issue/52/the-hive/modern-media-is-a-dos-attack-on-your-free-will

[^34] Facebook’s login page welcomes users with these words: “\[c\]onnect with friends and the world around you on Facebook”, not mentioning the price of collecting data and receiving personalized advertising, or how hard it is technically and psychologically to disconnect from Facebook. Twitter also opens with the promise of connecting and keeping you updated, avoiding the topic of advertisement.

[^35] Facebook, Annual reports, 2016. investor.fb.com/financials/?section=annualreports (accessed January 1, 2018)

[^36] Tencent, Annual Report, 2016. tencent.com/en-us/investor.html (accessed January 1, 2018)

[^37] Twitter, Annual report, 2016. investor.twitterinc.com/annuals-proxies.cfm (accessed January 1, 2018)

[^38] Sean Parker: Facebook was designed to exploit human “vulnerability”, Nov 9, 2017, axios.com/sean-parker-facebook-exploits-a-vulnerability-in-humans-2507917325.html (accessed January 1, 2018)

[^39] Wilshere, Andrew: Are Notifications A Dark Pattern? 2017, trydesignlab.com/blog/are-notifications-a-dark-pattern-ux-ui/ (accessed January 30, 2018)

[^40] Pielot, M., Church, K. and Oliveira, R: “An In-Situ Study of Mobile Phone Notifications” MobileHCI ’14, September 23 - 26 2014, Toronto. pielot.org/pubs/Pielot2014-MobileHCI-Notifications.pdf (accessed January 1, 2018)

[^41] Gallud, Jose A. Tesoriero, Ricardo. Smartphone Notifications: A Study on the Sound to Soundless Tendency. Denmark, 2015. Proceeding MobileHCI ‘15 Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct, P. 819-824 dl.acm.org/citation.cfm?id=2793706 (accessed January 1, 2018)

[^42] Pew Research Center: The Smartphone Difference. April, 2015. pewinternet.org/2015/04/01/us-smartphone-use-in-2015/ (accessed January 1, 2018)

[^43] Eyal, Nir. Hooked: How to Build Habit-forming Products. Ebook. NY, NY: Portfolio/Penguin, 2014.

[^44] Ibid.

[^45] Ibid. chapter 6. What Are You Going to Do with This?

[^46] Ind.ie: Ethical Design Manifesto. ind.ie/ethical-design/ (accessed January 1, 2018)

[^47] Zuboff, S: “Big other: surveillance capitalism and the prospects of an information civilization”

Journal of Information Technology, 201\. 30: 75. doi.org/10.1057/jit.2015.5 (accessed January 1, 2018)

[^48] Williams, J. Orwell, Huxley, Banksy. Rough Consensus, May 24, 2014, blogs.oii.ox.ac.uk/roughconsensus/2014/05/orwell-huxley-banksy/ (accessed January 1, 2018)

[^49] Time Well Spent, 2017, timewellspent.io/ (accessed January 1, 2018)

[^50] Ibid.

[^51] This is also the reason why I conducted the interviews with designers from the different walks of the field on these same 3 levels: the overall systemic possibilities for change, the business model of clients and how a designer can influence in that area, and the possibilities to make a difference through the design process and research.)
